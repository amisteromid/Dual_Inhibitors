{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bbc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73797534",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = pd.read_csv(\"final_IGF1R.csv\", low_memory=False, index_col=0)\n",
    "f = pd.read_csv(\"final_FGFR4.csv\", low_memory=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d04996d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes vertically\n",
    "#i['target'] = 'IGF1R'\n",
    "#f['target'] = 'FGFR4'\n",
    "#df = pd.concat([i, f], ignore_index=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1f27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi = i.drop(columns=['pIC50','smile'])\n",
    "yi = i['pIC50']\n",
    "Xi_train, Xi_test, yi_train, yi_test = train_test_split(Xi, yi, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "Xf = f.drop(columns=['pIC50','smile'])\n",
    "yf = f['pIC50']\n",
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(Xf, yf, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2bbb24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGF1R\n",
      "Number of columns before any filter: 2308\n",
      "Number of columns after removing low variance columns: 1462\n",
      "Number of columns after removing highly correlated columns: 182\n",
      "FGFR4\n",
      "Number of columns before any filter: 2308\n",
      "Number of columns after removing low variance columns: 1309\n",
      "Number of columns after removing highly correlated columns: 152\n"
     ]
    }
   ],
   "source": [
    "def filter_features(df,test_df):\n",
    "    print(\"Number of columns before any filter:\", len(df.columns))\n",
    "    \n",
    "    variances = df.var()\n",
    "    low_variance_threshold = 0.01  # Adjust as needed\n",
    "    low_variance_columns = variances[variances < low_variance_threshold].index\n",
    "    df = df.drop(columns=low_variance_columns)\n",
    "    test_df = test_df.drop(columns=low_variance_columns)\n",
    "    print(\"Number of columns after removing low variance columns:\", len(df.columns))\n",
    "    \n",
    "    correlation_matrix = df.corr()\n",
    "    high_correlation_threshold = 0.8  # Adjust as needed\n",
    "    high_correlation_pairs = np.where(np.abs(correlation_matrix) > high_correlation_threshold)\n",
    "    high_correlation_pairs_set = {(df.columns[i], df.columns[j])\n",
    "                                  for i, j in zip(*high_correlation_pairs) if i != j}\n",
    "    columns_to_remove = [col[0] for col in high_correlation_pairs_set]\n",
    "    df = df.drop(columns=columns_to_remove)\n",
    "    test_df = test_df.drop(columns=columns_to_remove)\n",
    "    print(\"Number of columns after removing highly correlated columns:\", len(df.columns))\n",
    "    return df, test_df\n",
    "    \n",
    "print (\"IGF1R\")\n",
    "Xi_train, Xi_test = filter_features(Xi_train, Xi_test)\n",
    "print (\"FGFR4\")\n",
    "Xf_train, Xf_test = filter_features(Xf_train, Xf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774a31fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGFR4\n",
      "(0.8968535601083691, 'PEOE_VSA2')\n",
      "(0.8062632551209514, 'SlogP_VSA10')\n",
      "(0.7225010980752868, 'MDEC-33')\n",
      "(0.6714001903992104, 'PEOE_VSA9')\n",
      "(0.6564571050493808, 'PEOE_VSA10')\n",
      "(0.6489522186097876, 'EState_VSA8')\n",
      "(0.6479546299519168, 'SlogP_VSA3')\n",
      "(0.6360444544248391, 'EState_VSA2')\n",
      "(0.6043462232352712, 'PEOE_VSA3')\n",
      "(0.601931899739641, 'PEOE_VSA1')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 and Random Forest is done! \tbest score is 0.5823094265318045\n",
      "25 and Random Forest is done! \tbest score is 0.5785183613939446\n",
      "30 and Random Forest is done! \tbest score is 0.5866815444387227\n",
      "35 and Random Forest is done! \tbest score is 0.5827928715001158\n",
      "40 and Random Forest is done! \tbest score is 0.5814083273183264\n",
      "20 and Support Vector Machine is done! \tbest score is 0.5334800842842082\n",
      "25 and Support Vector Machine is done! \tbest score is 0.49818055442609643\n",
      "30 and Support Vector Machine is done! \tbest score is 0.5113609136192643\n",
      "35 and Support Vector Machine is done! \tbest score is 0.5066702046700677\n",
      "40 and Support Vector Machine is done! \tbest score is 0.5139003780041956\n",
      "20 and XGBoost is done! \tbest score is 0.5762311120246201\n",
      "25 and XGBoost is done! \tbest score is 0.5834355330233375\n",
      "30 and XGBoost is done! \tbest score is 0.5805547322815322\n",
      "35 and XGBoost is done! \tbest score is 0.5778884428960949\n",
      "40 and XGBoost is done! \tbest score is 0.5746078330890765\n",
      "20 and Gradient Boosting Regression Trees is done! \tbest score is 0.5581107699907252\n",
      "25 and Gradient Boosting Regression Trees is done! \tbest score is 0.565312016563251\n",
      "30 and Gradient Boosting Regression Trees is done! \tbest score is 0.5677535250428927\n",
      "35 and Gradient Boosting Regression Trees is done! \tbest score is 0.5671832272862489\n",
      "40 and Gradient Boosting Regression Trees is done! \tbest score is 0.5658256574349574\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Optimal Number of Features</th>\n",
       "      <th>Optimal Hyperparameters</th>\n",
       "      <th>Q2</th>\n",
       "      <th>MSEcv</th>\n",
       "      <th>R2train</th>\n",
       "      <th>MSEtrain</th>\n",
       "      <th>R2test</th>\n",
       "      <th>MSEtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 200}</td>\n",
       "      <td>0.586682</td>\n",
       "      <td>0.581408</td>\n",
       "      <td>0.938059</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.603936</td>\n",
       "      <td>0.347830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>20</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.533480</td>\n",
       "      <td>0.513900</td>\n",
       "      <td>0.759235</td>\n",
       "      <td>0.264704</td>\n",
       "      <td>0.505601</td>\n",
       "      <td>0.434190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>25</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 100}</td>\n",
       "      <td>0.583436</td>\n",
       "      <td>0.574608</td>\n",
       "      <td>0.952010</td>\n",
       "      <td>0.052761</td>\n",
       "      <td>0.541364</td>\n",
       "      <td>0.402782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Regression Trees</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.567754</td>\n",
       "      <td>0.565826</td>\n",
       "      <td>0.971001</td>\n",
       "      <td>0.031883</td>\n",
       "      <td>0.586099</td>\n",
       "      <td>0.363494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Method  Optimal Number of Features  \\\n",
       "0                       Random Forest                          30   \n",
       "1              Support Vector Machine                          20   \n",
       "2                             XGBoost                          25   \n",
       "3  Gradient Boosting Regression Trees                          30   \n",
       "\n",
       "                       Optimal Hyperparameters        Q2     MSEcv   R2train  \\\n",
       "0       {'max_depth': 20, 'n_estimators': 200}  0.586682  0.581408  0.938059   \n",
       "1                   {'C': 10, 'kernel': 'rbf'}  0.533480  0.513900  0.759235   \n",
       "2  {'learning_rate': 0.1, 'n_estimators': 100}  0.583436  0.574608  0.952010   \n",
       "3        {'max_depth': 5, 'n_estimators': 200}  0.567754  0.565826  0.971001   \n",
       "\n",
       "   MSEtrain    R2test   MSEtest  \n",
       "0  0.068100  0.603936  0.347830  \n",
       "1  0.264704  0.505601  0.434190  \n",
       "2  0.052761  0.541364  0.402782  \n",
       "3  0.031883  0.586099  0.363494  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"FGFR4\")\n",
    "\n",
    "# Calculate mutual information between features and the target 'pIC50'\n",
    "mutual_info = mutual_info_regression(Xf_train, yf_train)\n",
    "\n",
    "# Sort features by mutual information in descending order\n",
    "sorted_features = [f for _, f in sorted(zip(mutual_info, Xf_train.columns), reverse=True)]\n",
    "for i in sorted(zip(mutual_info, Xf_train.columns), reverse=True)[:10]:\n",
    "    print (i)\n",
    "\n",
    "# Create a histogram plot of the mutual information scores\n",
    "plt.hist(mutual_info, bins=20, edgecolor='black')\n",
    "plt.xlabel('Mutual Information Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Mutual Information Scores')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define models and their hyperparameter grids\n",
    "# Define the models and their respective hyperparameter grids\n",
    "models = {\n",
    "    'Random Forest': (RandomForestRegressor(),\n",
    "                      {'n_estimators': [200], 'max_depth': [None, 10, 20]}),\n",
    "    'Support Vector Machine': (SVR(),\n",
    "                               {'C': [10], 'kernel': ['rbf']}),\n",
    "    'XGBoost': (XGBRegressor(),\n",
    "                {'learning_rate': [0.1], 'n_estimators': [100, 200, 300]}),\n",
    "    'Gradient Boosting Regression Trees': (GradientBoostingRegressor(),\n",
    "                                           {'n_estimators': [200], 'max_depth': [5]})\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize results table\n",
    "results = []\n",
    "\n",
    "# Perform analysis for each model\n",
    "for name, (model, params) in models.items():\n",
    "    # Hyperparameter tuning and feature selection\n",
    "    best_score = -np.inf\n",
    "    best_features = None\n",
    "    best_params = None\n",
    "\n",
    "    for n_features in range(20, 41,5):\n",
    "        # Select top N features\n",
    "        Xf_train_selected = Xf_train[sorted_features[:n_features]]\n",
    "\n",
    "        # 5-fold cross-validation and hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, params, cv=8, scoring='r2', return_train_score=True)\n",
    "        grid_search.fit(Xf_train_selected, yf_train)\n",
    "\n",
    "        if grid_search.best_score_ > best_score:\n",
    "            best_score = grid_search.best_score_\n",
    "            best_features = sorted_features[:n_features]\n",
    "            best_params = grid_search.best_params_\n",
    "            best_num_features = n_features\n",
    "        print (n_features, \"and\", name, \"is done!\", \"\\tbest score is\", grid_search.best_score_)\n",
    "\n",
    "    # Train model with optimal hyperparameters and number of features\n",
    "    optimal_model = model.set_params(**best_params)\n",
    "    optimal_model.fit(Xf_train[best_features], yf_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred_train = optimal_model.predict(Xf_train[best_features])\n",
    "    y_pred_test = optimal_model.predict(Xf_test[best_features])\n",
    "    mse_cv = abs(grid_search.best_score_)\n",
    "    r2_train = r2_score(yf_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(yf_train, y_pred_train)\n",
    "    r2_test = r2_score(yf_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(yf_test, y_pred_test)\n",
    "\n",
    "    # Store results\n",
    "    results.append([name, best_num_features, best_params, best_score, mse_cv, r2_train, mse_train, r2_test, mse_test])\n",
    "\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Method', 'Optimal Number of Features', 'Optimal Hyperparameters', 'Q2', 'MSEcv', 'R2train', 'MSEtrain', 'R2test', 'MSEtest'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e7036",
   "metadata": {},
   "source": [
    "* All models show moderate to high accuracy on training data, with Gradient Boosting Regression Trees having the highest R2train and the lowest MSEtrain.\n",
    "* For cross-validation and test performance, the Random Forest model shows slightly better generalizability (higher Q2 and R2test) than the others, though the differences are not very large.\n",
    "* The Support Vector Machine has comparatively lower performance metrics across all categories.\n",
    "* It's important to note that while R2train is high for all models, the Q2 values are moderate, indicating some overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44be1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGF1R\n",
      "(0.5148058952871977, 'SlogP_VSA8')\n",
      "(0.42952802221384534, 'EState_VSA9')\n",
      "(0.40426373426873585, 'SlogP_VSA10')\n",
      "(0.4039947165546618, 'VSA_EState3')\n",
      "(0.35533312263870176, 'SlogP_VSA1')\n",
      "(0.3285201912573372, 'BCUTs-1h')\n",
      "(0.3185035943433103, 'PEOE_VSA2')\n",
      "(0.31456144717310197, 'SMR_VSA9')\n",
      "(0.29919567575996275, 'MDEC-33')\n",
      "(0.29631242890508824, 'PEOE_VSA9')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 and Random Forest is done! \tbest score is 0.7469712332824181\n",
      "55 and Random Forest is done! \tbest score is 0.7506056665294794\n",
      "60 and Random Forest is done! \tbest score is 0.7511312392885827\n",
      "65 and Random Forest is done! \tbest score is 0.7514744616326365\n",
      "70 and Random Forest is done! \tbest score is 0.7474554444134953\n",
      "50 and Support Vector Machine is done! \tbest score is 0.664188888993493\n",
      "55 and Support Vector Machine is done! \tbest score is 0.5662576680727022\n",
      "60 and Support Vector Machine is done! \tbest score is 0.5648714824072312\n",
      "65 and Support Vector Machine is done! \tbest score is 0.5239127933723398\n",
      "70 and Support Vector Machine is done! \tbest score is 0.5061009015126172\n",
      "50 and XGBoost is done! \tbest score is 0.7565712713236166\n",
      "55 and XGBoost is done! \tbest score is 0.7576002640882629\n",
      "60 and XGBoost is done! \tbest score is 0.7596600898634159\n",
      "65 and XGBoost is done! \tbest score is 0.7598499653910904\n",
      "70 and XGBoost is done! \tbest score is 0.7646619366501495\n",
      "50 and Gradient Boosting Regression Trees is done! \tbest score is 0.7498543205854518\n",
      "55 and Gradient Boosting Regression Trees is done! \tbest score is 0.7533748952836256\n",
      "60 and Gradient Boosting Regression Trees is done! \tbest score is 0.7496405067722476\n",
      "65 and Gradient Boosting Regression Trees is done! \tbest score is 0.7528241382766899\n",
      "70 and Gradient Boosting Regression Trees is done! \tbest score is 0.7581550152992441\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Optimal Number of Features</th>\n",
       "      <th>Optimal Hyperparameters</th>\n",
       "      <th>Q2</th>\n",
       "      <th>MSEcv</th>\n",
       "      <th>R2train</th>\n",
       "      <th>MSEtrain</th>\n",
       "      <th>R2test</th>\n",
       "      <th>MSEtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>65</td>\n",
       "      <td>{'max_depth': 20, 'n_estimators': 200}</td>\n",
       "      <td>0.751474</td>\n",
       "      <td>0.747455</td>\n",
       "      <td>0.965029</td>\n",
       "      <td>0.075875</td>\n",
       "      <td>0.783940</td>\n",
       "      <td>0.433716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>50</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.664189</td>\n",
       "      <td>0.506101</td>\n",
       "      <td>0.799038</td>\n",
       "      <td>0.436021</td>\n",
       "      <td>0.734267</td>\n",
       "      <td>0.533428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>70</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 200}</td>\n",
       "      <td>0.764662</td>\n",
       "      <td>0.764662</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.769199</td>\n",
       "      <td>0.463307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Regression Trees</td>\n",
       "      <td>70</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.758155</td>\n",
       "      <td>0.758155</td>\n",
       "      <td>0.981755</td>\n",
       "      <td>0.039585</td>\n",
       "      <td>0.769238</td>\n",
       "      <td>0.463229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Method  Optimal Number of Features  \\\n",
       "0                       Random Forest                          65   \n",
       "1              Support Vector Machine                          50   \n",
       "2                             XGBoost                          70   \n",
       "3  Gradient Boosting Regression Trees                          70   \n",
       "\n",
       "                       Optimal Hyperparameters        Q2     MSEcv   R2train  \\\n",
       "0       {'max_depth': 20, 'n_estimators': 200}  0.751474  0.747455  0.965029   \n",
       "1                   {'C': 10, 'kernel': 'rbf'}  0.664189  0.506101  0.799038   \n",
       "2  {'learning_rate': 0.1, 'n_estimators': 200}  0.764662  0.764662  0.993474   \n",
       "3        {'max_depth': 5, 'n_estimators': 200}  0.758155  0.758155  0.981755   \n",
       "\n",
       "   MSEtrain    R2test   MSEtest  \n",
       "0  0.075875  0.783940  0.433716  \n",
       "1  0.436021  0.734267  0.533428  \n",
       "2  0.014159  0.769199  0.463307  \n",
       "3  0.039585  0.769238  0.463229  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"IGF1R\")\n",
    "\n",
    "# Calculate mutual information between features and the target 'pIC50'\n",
    "mutual_info = mutual_info_regression(Xi_train, yi_train)\n",
    "\n",
    "# Sort features by mutual information in descending order\n",
    "sorted_features = [f for _, f in sorted(zip(mutual_info, Xi_train.columns), reverse=True)]\n",
    "for i in sorted(zip(mutual_info, Xi_train.columns), reverse=True)[:10]:\n",
    "    print (i)\n",
    "\n",
    "# Create a histogram plot of the mutual information scores\n",
    "plt.hist(mutual_info, bins=20, edgecolor='black')\n",
    "plt.xlabel('Mutual Information Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Mutual Information Scores')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define models and their hyperparameter grids\n",
    "# Define the models and their respective hyperparameter grids\n",
    "models = {\n",
    "    'Random Forest': (RandomForestRegressor(),\n",
    "                      {'n_estimators': [200], 'max_depth': [None, 10, 20]}),\n",
    "    'Support Vector Machine': (SVR(),\n",
    "                               {'C': [10], 'kernel': ['rbf']}),\n",
    "    'XGBoost': (XGBRegressor(),\n",
    "                {'learning_rate': [0.1], 'n_estimators': [100, 200, 300]}),\n",
    "    'Gradient Boosting Regression Trees': (GradientBoostingRegressor(),\n",
    "                                           {'n_estimators': [200], 'max_depth': [5]})\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Initialize results table\n",
    "results = []\n",
    "\n",
    "# Perform analysis for each model\n",
    "for name, (model, params) in models.items():\n",
    "    # Hyperparameter tuning and feature selection\n",
    "    best_score = -np.inf\n",
    "    best_features = None\n",
    "    best_params = None\n",
    "\n",
    "    for n_features in range(50, 71,5):\n",
    "        # Select top N features\n",
    "        Xi_train_selected = Xi_train[sorted_features[:n_features]]\n",
    "\n",
    "        # 5-fold cross-validation and hyperparameter tuning\n",
    "        grid_search = GridSearchCV(model, params, cv=8, scoring='r2', return_train_score=True)\n",
    "        grid_search.fit(Xi_train_selected, yi_train)\n",
    "\n",
    "        if grid_search.best_score_ > best_score:\n",
    "            best_score = grid_search.best_score_\n",
    "            best_features = sorted_features[:n_features]\n",
    "            best_params = grid_search.best_params_\n",
    "            best_num_features = n_features\n",
    "        print (n_features, \"and\", name, \"is done!\", \"\\tbest score is\", grid_search.best_score_)\n",
    "\n",
    "    # Train model with optimal hyperparameters and number of features\n",
    "    optimal_model = model.set_params(**best_params)\n",
    "    optimal_model.fit(Xi_train[best_features], yi_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred_train = optimal_model.predict(Xi_train[best_features])\n",
    "    y_pred_test = optimal_model.predict(Xi_test[best_features])\n",
    "    mse_cv = abs(grid_search.best_score_)\n",
    "    r2_train = r2_score(yi_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(yi_train, y_pred_train)\n",
    "    r2_test = r2_score(yi_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(yi_test, y_pred_test)\n",
    "\n",
    "    # Store results\n",
    "    results.append([name, best_num_features, best_params, best_score, mse_cv, r2_train, mse_train, r2_test, mse_test])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['Method', 'Optimal Number of Features', 'Optimal Hyperparameters', 'Q2', 'MSEcv', 'R2train', 'MSEtrain', 'R2test', 'MSEtest'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d11d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
